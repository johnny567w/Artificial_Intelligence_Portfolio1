{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6364120a",
   "metadata": {},
   "source": [
    "# Segundo notebook\n",
    "A continuacion se prepara un indice reproducble de las imaganes, como solo buscamos car, truck y airplane se enfocara unicamente en esas \n",
    "\n",
    "Este notebook:\n",
    "- Lee las anotaciones COCO (train y opcionalmente val)\n",
    "- Filtra solo las clases objetivo\n",
    "- Selecciona un subconjunto limitado de imágenes por clase (para entrenar rápido)\n",
    "- Genera archivos índice (manifests) que usará el Notebook 02\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca14fbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- IMPORTS ---\n",
    "from pathlib import Path\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Dict, List, Tuple, Set\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "391aae36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: c:\\Users\\Johnny\\Desktop\\IA\n",
      "COCO_ROOT: C:\\Users\\Johnny\\Desktop\\IA\\data\\archive\\coco2017\n",
      "DATASET_INDEX_DIR: c:\\Users\\Johnny\\Desktop\\IA\\artifacts\\dataset_index\n"
     ]
    }
   ],
   "source": [
    "# --- RUTAS  ---\n",
    "#solo para confirmar se declara las rutas establecidad previamente\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent\n",
    "\n",
    "COCO_ROOT = Path(r\"C:\\Users\\Johnny\\Desktop\\IA\\data\\archive\\coco2017\")\n",
    "COCO_ANN_DIR = COCO_ROOT / \"annotations\"\n",
    "COCO_TRAIN_IMG_DIR = COCO_ROOT / \"train2017\"\n",
    "COCO_VAL_IMG_DIR = COCO_ROOT / \"val2017\"\n",
    "\n",
    "COCO_INSTANCES_TRAIN = COCO_ANN_DIR / \"instances_train2017.json\"\n",
    "COCO_INSTANCES_VAL = COCO_ANN_DIR / \"instances_val2017.json\"\n",
    "\n",
    "ARTIFACTS_DIR = PROJECT_ROOT / \"artifacts\"\n",
    "DATASET_INDEX_DIR = ARTIFACTS_DIR / \"dataset_index\"\n",
    "\n",
    "CLASS_MAP_PATH = ARTIFACTS_DIR / \"class_map.json\"\n",
    "CONFIG_SNAPSHOT_PATH = ARTIFACTS_DIR / \"config_snapshot.json\"\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"COCO_ROOT:\", COCO_ROOT)\n",
    "print(\"DATASET_INDEX_DIR:\", DATASET_INDEX_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7720b4",
   "metadata": {},
   "source": [
    "1. Carga de configuraciones previas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c681d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validaciones OK.\n"
     ]
    }
   ],
   "source": [
    "#De igualmanera para evitar problemas se hace una validacion simple de carpetas, para evitar fallos mas que nada\n",
    "# --- VALIDACIONES BÁSICAS ---\n",
    "def assert_exists(p: Path, desc: str) -> None:\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Falta {desc}: {p}\")\n",
    "\n",
    "assert_exists(COCO_ROOT, \"carpeta COCO_ROOT\")\n",
    "assert_exists(COCO_ANN_DIR, \"carpeta annotations\")\n",
    "assert_exists(COCO_TRAIN_IMG_DIR, \"carpeta train2017\")\n",
    "assert_exists(COCO_INSTANCES_TRAIN, \"archivo instances_train2017.json\")\n",
    "\n",
    "assert_exists(ARTIFACTS_DIR, \"carpeta artifacts (debe existir por el Notebook 00)\")\n",
    "assert_exists(CLASS_MAP_PATH, \"class_map.json (debe existir por el Notebook 00)\")\n",
    "assert_exists(CONFIG_SNAPSHOT_PATH, \"config_snapshot.json (debe existir por el Notebook 00)\")\n",
    "\n",
    "DATASET_INDEX_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Validaciones OK.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c33ed8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases objetivo: ('car', 'airplane', 'truck')\n",
      "Límite train por clase: 900\n",
      "Límite val por clase: 300\n",
      "Seed: 42\n"
     ]
    }
   ],
   "source": [
    "#Cargamos las limitaciones del dataset previo\n",
    "# --- CARGA DE CONFIGURACIÓN DEL PROYECTO ---\n",
    "with open(CONFIG_SNAPSHOT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "with open(CLASS_MAP_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    class_map = json.load(f)\n",
    "\n",
    "target_classes = tuple(cfg[\"target_classes\"])\n",
    "max_train = int(cfg[\"max_images_per_class_train\"])\n",
    "max_val = int(cfg[\"max_images_per_class_val\"])\n",
    "seed = int(cfg[\"seed\"])\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "print(\"Clases objetivo:\", target_classes)\n",
    "print(\"Límite train por clase:\", max_train)\n",
    "print(\"Límite val por clase:\", max_val)\n",
    "print(\"Seed:\", seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a222d846",
   "metadata": {},
   "source": [
    "2. Configuracion del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9c92f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define funciones utilitarias para leer y organizar un dataset en formato COCO igualmanera usa el json creado previaene\n",
    "# --- FUNCIONES PARA PARSEAR COCO ---\n",
    "def load_coco(path_json: Path) -> Dict:\n",
    "    with open(path_json, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def build_cat_maps(coco: Dict) -> Tuple[Dict[str, int], Dict[int, str]]:\n",
    "    categories = coco.get(\"categories\", [])\n",
    "    name_to_id = {c[\"name\"]: c[\"id\"] for c in categories}\n",
    "    id_to_name = {c[\"id\"]: c[\"name\"] for c in categories}\n",
    "    return name_to_id, id_to_name\n",
    "\n",
    "def build_image_map(coco: Dict) -> Dict[int, Dict]:\n",
    "    images = coco.get(\"images\", [])\n",
    "    return {img[\"id\"]: img for img in images}\n",
    "\n",
    "def build_annotations_by_image(coco: Dict) -> Dict[int, List[Dict]]:\n",
    "    ann_by_img = defaultdict(list)\n",
    "    for ann in coco.get(\"annotations\", []):\n",
    "        ann_by_img[ann[\"image_id\"]].append(ann)\n",
    "    return ann_by_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70bdaf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: instances_val2017.json encontrado.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- CARGA COCO TRAIN  ---\n",
    "coco_train = load_coco(COCO_INSTANCES_TRAIN)\n",
    "train_name_to_id, train_id_to_name = build_cat_maps(coco_train)\n",
    "train_images = build_image_map(coco_train)\n",
    "train_ann_by_img = build_annotations_by_image(coco_train)\n",
    "\n",
    "has_val_file = COCO_INSTANCES_VAL.exists()\n",
    "\n",
    "if has_val_file:\n",
    "    coco_val = load_coco(COCO_INSTANCES_VAL)\n",
    "    val_name_to_id, val_id_to_name = build_cat_maps(coco_val)\n",
    "    val_images = build_image_map(coco_val)\n",
    "    val_ann_by_img = build_annotations_by_image(coco_val)\n",
    "    print(\"OK: instances_val2017.json encontrado.\")\n",
    "else:\n",
    "    coco_val = None\n",
    "    val_name_to_id, val_id_to_name = {}, {}\n",
    "    val_images, val_ann_by_img = {}, {}\n",
    "    print(\"Aviso: no hay instances_val2017.json. Se hará split desde train.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba46e461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category IDs (train):\n",
      "- car -> 3\n",
      "- airplane -> 5\n",
      "- truck -> 8\n"
     ]
    }
   ],
   "source": [
    "#Validaciones de las clases coco necesarias, json y formatos correctos\n",
    "# --- VALIDAR QUE LAS CLASES OBJETIVO EXISTEN EN COCO ---\n",
    "missing = [c for c in target_classes if c not in train_name_to_id]\n",
    "if missing:\n",
    "    raise ValueError(f\"Clases faltantes en COCO train categories: {missing}\")\n",
    "\n",
    "target_cat_ids_train = {train_name_to_id[c] for c in target_classes}\n",
    "\n",
    "print(\"Category IDs (train):\")\n",
    "for c in target_classes:\n",
    "    print(\"-\", c, \"->\", train_name_to_id[c])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f25b843",
   "metadata": {},
   "source": [
    "3. Seleccion de imagenes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e31e69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidatos (train) por clase (imágenes únicas):\n",
      "- car : 12,251\n",
      "- airplane : 2,986\n",
      "- truck : 6,127\n"
     ]
    }
   ],
   "source": [
    "#Este bloque construye, para cada clase objetivo, la lista de imágenes que la contienen ayuda a balancear, filtrar y depurar el dataset\n",
    "# --- CONSTRUIR LISTAS DE CANDIDATOS POR CLASE (IMÁGENES QUE CONTIENEN LA CLASE) ---\n",
    "def images_by_class(images_map: Dict[int, Dict],\n",
    "                    ann_by_img: Dict[int, List[Dict]],\n",
    "                    target_cat_ids: Set[int]) -> Dict[int, Set[int]]:\n",
    "    class_to_imgs = defaultdict(set)\n",
    "    for img_id, anns in ann_by_img.items():\n",
    "        for a in anns:\n",
    "            cid = a.get(\"category_id\")\n",
    "            if cid in target_cat_ids:\n",
    "                class_to_imgs[cid].add(img_id)\n",
    "    return class_to_imgs\n",
    "\n",
    "train_class_to_imgs = images_by_class(train_images, train_ann_by_img, target_cat_ids_train)\n",
    "\n",
    "print(\"Candidatos (train) por clase (imágenes únicas):\")\n",
    "for c in target_classes:\n",
    "    cid = train_name_to_id[c]\n",
    "    print(\"-\", c, \":\", f\"{len(train_class_to_imgs[cid]):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd476aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágenes seleccionadas (train): 2341\n"
     ]
    }
   ],
   "source": [
    "#esta seccion ayuda a evitar un desbalance de imagenes, como se vio en el primer notebook\n",
    "#  existe una categoria con mas ejemplares y para evitar falsos positovos que solo identififique esa categora especifica a la fuerza se debe balancear el numero de imagenes\n",
    "# --- SELECCIÓN BALANCEADA DE IMÁGENES (GREEDY) ---\n",
    "def select_balanced_images(class_to_imgs: Dict[int, Set[int]],\n",
    "                           cat_ids: List[int],\n",
    "                           per_class_limit: int,\n",
    "                           seed: int) -> List[int]:\n",
    "    rng = random.Random(seed)\n",
    "    remaining = {cid: set(imgs) for cid, imgs in class_to_imgs.items()}\n",
    "    selected: List[int] = []\n",
    "    selected_set: Set[int] = set()\n",
    "    counts = {cid: 0 for cid in cat_ids}\n",
    "\n",
    "    pool = set().union(*[remaining.get(cid, set()) for cid in cat_ids])\n",
    "    pool = list(pool)\n",
    "    rng.shuffle(pool)\n",
    "\n",
    "    def img_classes(img_id: int) -> List[int]:\n",
    "        present = []\n",
    "        for cid in cat_ids:\n",
    "            if img_id in remaining.get(cid, set()):\n",
    "                present.append(cid)\n",
    "        return present\n",
    "\n",
    "    for img_id in pool:\n",
    "        present = img_classes(img_id)\n",
    "        if not present:\n",
    "            continue\n",
    "\n",
    "        can_help = any(counts[cid] < per_class_limit for cid in present)\n",
    "        if not can_help:\n",
    "            continue\n",
    "\n",
    "        if img_id not in selected_set:\n",
    "            selected.append(img_id)\n",
    "            selected_set.add(img_id)\n",
    "\n",
    "        for cid in present:\n",
    "            if counts[cid] < per_class_limit:\n",
    "                counts[cid] += 1\n",
    "\n",
    "        if all(counts[cid] >= per_class_limit for cid in cat_ids):\n",
    "            break\n",
    "\n",
    "    return selected\n",
    "\n",
    "cat_ids_order = [train_name_to_id[c] for c in target_classes]\n",
    "\n",
    "selected_train_img_ids = select_balanced_images(\n",
    "    train_class_to_imgs,\n",
    "    cat_ids_order,\n",
    "    per_class_limit=max_train,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "print(\"Imágenes seleccionadas (train):\", len(selected_train_img_ids))\n",
    "#imagenes seleccionas es del conjunto total de todo el datatset se entrenara solo con una fraccion del mismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92699f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presencia por clase (train subset):\n",
      "- car : 1246\n",
      "- airplane : 900\n",
      "- truck : 993\n"
     ]
    }
   ],
   "source": [
    "# --- CONTEO REAL POR CLASE EN EL SUBCONJUNTO SELECCIONADO ---\n",
    "def count_presence_by_class(img_ids: List[int],\n",
    "                            ann_by_img: Dict[int, List[Dict]],\n",
    "                            cat_ids: List[int]) -> Dict[int, int]:\n",
    "    counts = {cid: 0 for cid in cat_ids}\n",
    "    img_set = set(img_ids)\n",
    "    for img_id in img_set:\n",
    "        anns = ann_by_img.get(img_id, [])\n",
    "        present = set(a[\"category_id\"] for a in anns)\n",
    "        for cid in cat_ids:\n",
    "            if cid in present:\n",
    "                counts[cid] += 1\n",
    "    return counts\n",
    "\n",
    "train_presence_counts = count_presence_by_class(\n",
    "    selected_train_img_ids, train_ann_by_img, cat_ids_order\n",
    ")\n",
    "\n",
    "print(\"Presencia por clase (train subset):\")\n",
    "for c in target_classes:\n",
    "    cid = train_name_to_id[c]\n",
    "    print(\"-\", c, \":\", train_presence_counts[cid])\n",
    "    #Para el trainig se seleccionarios 1246 imagenes de autos, 900 de aviones y 994 de carros grandes/tractores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1631b3c",
   "metadata": {},
   "source": [
    "4. Construccion de formato listo para YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "676b63e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágenes seleccionadas (val oficial): 550\n"
     ]
    }
   ],
   "source": [
    "#Este bloque crea el conjunto de validación de forma segura y reproducible, usando VAL oficial si existe o generándolo desde TRAIN si no.\n",
    "# --- ARMAR VAL: USAR VAL OFICIAL SI EXISTE, SI NO HACER SPLIT DESDE TRAIN ---\n",
    "def build_subset_manifest(coco: Dict,\n",
    "                          images_map: Dict[int, Dict],\n",
    "                          ann_by_img: Dict[int, List[Dict]],\n",
    "                          selected_img_ids: List[int],\n",
    "                          target_cat_ids: Set[int]) -> Dict:\n",
    "    selected_set = set(selected_img_ids)\n",
    "\n",
    "    images_out = []\n",
    "    annotations_out = []\n",
    "    ann_id_counter = 1\n",
    "\n",
    "    for img_id in selected_img_ids:\n",
    "        if img_id not in images_map:\n",
    "            continue\n",
    "        images_out.append(images_map[img_id])\n",
    "\n",
    "        for ann in ann_by_img.get(img_id, []):\n",
    "            if ann[\"category_id\"] in target_cat_ids:\n",
    "                ann_copy = dict(ann)\n",
    "                ann_copy[\"id\"] = ann_id_counter\n",
    "                ann_id_counter += 1\n",
    "                annotations_out.append(ann_copy)\n",
    "\n",
    "    categories_out = [c for c in coco.get(\"categories\", []) if c[\"id\"] in target_cat_ids]\n",
    "\n",
    "    out = {\n",
    "        \"images\": images_out,\n",
    "        \"annotations\": annotations_out,\n",
    "        \"categories\": categories_out\n",
    "    }\n",
    "    return out\n",
    "\n",
    "if has_val_file:\n",
    "    val_missing = [c for c in target_classes if c not in val_name_to_id]\n",
    "    if val_missing:\n",
    "        print(\"Aviso: en VAL faltan clases:\", val_missing)\n",
    "    target_cat_ids_val = {val_name_to_id[c] for c in target_classes if c in val_name_to_id}\n",
    "\n",
    "    val_class_to_imgs = images_by_class(val_images, val_ann_by_img, target_cat_ids_val)\n",
    "    val_cat_ids_order = [val_name_to_id[c] for c in target_classes if c in val_name_to_id]\n",
    "\n",
    "    selected_val_img_ids = select_balanced_images(\n",
    "        val_class_to_imgs,\n",
    "        val_cat_ids_order,\n",
    "        per_class_limit=max_val,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    val_manifest = build_subset_manifest(\n",
    "        coco_val,\n",
    "        val_images,\n",
    "        val_ann_by_img,\n",
    "        selected_val_img_ids,\n",
    "        target_cat_ids_val\n",
    "    )\n",
    "\n",
    "    print(\"Imágenes seleccionadas (val oficial):\", len(selected_val_img_ids))\n",
    "\n",
    "else:\n",
    "    val_ratio = 0.2\n",
    "    shuffled = selected_train_img_ids[:]\n",
    "    random.shuffle(shuffled)\n",
    "\n",
    "    val_size = max(1, int(len(shuffled) * val_ratio))\n",
    "    selected_val_img_ids = shuffled[:val_size]\n",
    "    selected_train_img_ids = shuffled[val_size:]\n",
    "\n",
    "    train_manifest = build_subset_manifest(\n",
    "        coco_train,\n",
    "        train_images,\n",
    "        train_ann_by_img,\n",
    "        selected_train_img_ids,\n",
    "        target_cat_ids_train\n",
    "    )\n",
    "\n",
    "    val_manifest = build_subset_manifest(\n",
    "        coco_train,\n",
    "        train_images,\n",
    "        train_ann_by_img,\n",
    "        selected_val_img_ids,\n",
    "        target_cat_ids_train\n",
    "    )\n",
    "\n",
    "    print(\"Split hecho desde train.\")\n",
    "    print(\"Train images:\", len(selected_train_img_ids))\n",
    "    print(\"Val images:\", len(selected_val_img_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9afc314b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train manifest: 2341 images, 7862 anns\n",
      "Val manifest: 550 images, 1895 anns\n"
     ]
    }
   ],
   "source": [
    "# --- SI EXISTE VAL OFICIAL, CREAR TAMBIÉN EL MANIFEST TRAIN ---\n",
    "if has_val_file:\n",
    "    train_manifest = build_subset_manifest(\n",
    "        coco_train,\n",
    "        train_images,\n",
    "        train_ann_by_img,\n",
    "        selected_train_img_ids,\n",
    "        target_cat_ids_train\n",
    "    )\n",
    "\n",
    "print(\"Train manifest:\", len(train_manifest[\"images\"]), \"images,\", len(train_manifest[\"annotations\"]), \"anns\")\n",
    "print(\"Val manifest:\", len(val_manifest[\"images\"]), \"images,\", len(val_manifest[\"annotations\"]), \"anns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6e1279",
   "metadata": {},
   "source": [
    "Alista los datos para ser utilizados por los siguientes notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53162009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado:\n",
      "- c:\\Users\\Johnny\\Desktop\\IA\\artifacts\\dataset_index\\subset_train_coco.json\n",
      "- c:\\Users\\Johnny\\Desktop\\IA\\artifacts\\dataset_index\\subset_val_coco.json\n",
      "- c:\\Users\\Johnny\\Desktop\\IA\\artifacts\\dataset_index\\subset_meta.json\n"
     ]
    }
   ],
   "source": [
    "# --- GUARDAR ÍNDICES / MANIFESTS PARA EL NOTEBOOK 02 ---\n",
    "TRAIN_INDEX_PATH = DATASET_INDEX_DIR / \"subset_train_coco.json\"\n",
    "VAL_INDEX_PATH = DATASET_INDEX_DIR / \"subset_val_coco.json\"\n",
    "META_PATH = DATASET_INDEX_DIR / \"subset_meta.json\"\n",
    "\n",
    "with open(TRAIN_INDEX_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(train_manifest, f)\n",
    "\n",
    "with open(VAL_INDEX_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(val_manifest, f)\n",
    "\n",
    "meta = {\n",
    "    \"target_classes\": list(target_classes),\n",
    "    \"train_images_count\": len(train_manifest[\"images\"]),\n",
    "    \"train_annotations_count\": len(train_manifest[\"annotations\"]),\n",
    "    \"val_images_count\": len(val_manifest[\"images\"]),\n",
    "    \"val_annotations_count\": len(val_manifest[\"annotations\"]),\n",
    "    \"max_images_per_class_train\": max_train,\n",
    "    \"max_images_per_class_val\": max_val,\n",
    "    \"seed\": seed,\n",
    "    \"coco_root\": str(COCO_ROOT),\n",
    "    \"train_images_dir\": str(COCO_TRAIN_IMG_DIR),\n",
    "    \"val_images_dir\": str(COCO_VAL_IMG_DIR),\n",
    "    \"train_instances_json\": str(COCO_INSTANCES_TRAIN),\n",
    "    \"val_instances_json\": str(COCO_INSTANCES_VAL) if has_val_file else None\n",
    "}\n",
    "\n",
    "with open(META_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"Guardado:\")\n",
    "print(\"-\", TRAIN_INDEX_PATH)\n",
    "print(\"-\", VAL_INDEX_PATH)\n",
    "print(\"-\", META_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f718cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train subset stats:\n",
      "- airplane_bbox_count : 1572\n",
      "- airplane_image_presence : 900\n",
      "- car_bbox_count : 4602\n",
      "- car_image_presence : 1246\n",
      "- truck_bbox_count : 1688\n",
      "- truck_image_presence : 993\n",
      "\n",
      "Val subset stats:\n",
      "- airplane_bbox_count : 143\n",
      "- airplane_image_presence : 97\n",
      "- car_bbox_count : 1337\n",
      "- car_image_presence : 378\n",
      "- truck_bbox_count : 415\n",
      "- truck_image_presence : 250\n"
     ]
    }
   ],
   "source": [
    "#estos sn los datos que estan listos para ser usados por los siguientes notebooks \n",
    "def present_counts(manifest: Dict) -> Dict[str, int]:\n",
    "    cats = {c[\"id\"]: c[\"name\"] for c in manifest.get(\"categories\", [])}\n",
    "    ann_counts = Counter()\n",
    "    img_presence = defaultdict(set)\n",
    "\n",
    "    for ann in manifest.get(\"annotations\", []):\n",
    "        cid = ann[\"category_id\"]\n",
    "        ann_counts[cats[cid]] += 1\n",
    "        img_presence[cats[cid]].add(ann[\"image_id\"])\n",
    "\n",
    "    out = {}\n",
    "    for name in sorted(ann_counts.keys()):\n",
    "        out[f\"{name}_bbox_count\"] = int(ann_counts[name])\n",
    "        out[f\"{name}_image_presence\"] = int(len(img_presence[name]))\n",
    "    return out\n",
    "\n",
    "print(\"Train subset stats:\")\n",
    "for k, v in present_counts(train_manifest).items():\n",
    "    print(\"-\", k, \":\", v)\n",
    "\n",
    "print(\"\\nVal subset stats:\")\n",
    "for k, v in present_counts(val_manifest).items():\n",
    "    print(\"-\", k, \":\", v)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
