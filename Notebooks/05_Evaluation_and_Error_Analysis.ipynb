{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cb96591",
   "metadata": {},
   "source": [
    "# Sexto notebook\n",
    "\n",
    "En este penultimo notebook se  analiza el desempeño real del modelo entrenado para decidir\n",
    "si el bajo rendimiento (si existe) se debe a:\n",
    "- umbrales mal configurados\n",
    "- clases confundidas\n",
    "- pocos datos\n",
    "- o necesidad de más entrenamiento\n",
    "\n",
    "Este notebook:\n",
    "- Evalúa el modelo con distintos thresholds\n",
    "- Analiza predicciones incorrectas\n",
    "- Resume errores por clase\n",
    "- Ayuda a decidir si cambiar a dataset completo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a0a969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- IMPORTS ---\n",
    "from pathlib import Path\n",
    "import json\n",
    "from collections import defaultdict, Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f806ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- RUTAS DEL PROYECTO ---\n",
    "#rutas creadas en los previos notebooks\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent\n",
    "\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "YOLO_MODEL_PATH = MODELS_DIR / \"yolo_best.pt\"\n",
    "\n",
    "YOLO_DATASET_DIR = PROJECT_ROOT / \"data\" / \"processed\" / \"yolo_dataset\"\n",
    "DATA_YAML_PATH = YOLO_DATASET_DIR / \"data.yaml\"\n",
    "\n",
    "ARTIFACTS_DIR = PROJECT_ROOT / \"artifacts\"\n",
    "CONFIG_SNAPSHOT_PATH = ARTIFACTS_DIR / \"config_snapshot.json\"\n",
    "\n",
    "print(\"Modelo:\", YOLO_MODEL_PATH)\n",
    "print(\"Dataset:\", DATA_YAML_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45865893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- VALIDACIONES ---\n",
    "#es fundamental que ya exista el modelo entrenado y el yaml por eso de debe validar que existen y son consistentes\n",
    "def assert_exists(p: Path, desc: str) -> None:\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Falta {desc}: {p}\")\n",
    "\n",
    "assert_exists(YOLO_MODEL_PATH, \"modelo entrenado\")\n",
    "assert_exists(DATA_YAML_PATH, \"data.yaml\")\n",
    "\n",
    "print(\"Validaciones OK.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440ae367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CARGA DE CONFIGURACIÓN ---\n",
    "#carga del archivo .json del modelo yolo\n",
    "with open(CONFIG_SNAPSHOT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "cfg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6591c212",
   "metadata": {},
   "source": [
    "1. Validacion del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02418c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- IMPORTAR YOLO ---\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(str(YOLO_MODEL_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e4a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EVALUACIÓN BASE (THRESHOLDS POR DEFECTO) ---\n",
    "#Validacion de que si se haya cumpleido los parametros inciiales del rpimer notebook con respetco al consumo de datos, tamanano de imagenes y batch a usarse\n",
    "base_metrics = model.val(\n",
    "    data=str(DATA_YAML_PATH),\n",
    "    imgsz=cfg[\"img_size\"],\n",
    "    conf=cfg[\"conf_threshold\"],\n",
    "    iou=cfg[\"iou_threshold\"],\n",
    "    batch=cfg[\"batch_size\"]\n",
    ")\n",
    "\n",
    "print(\"Evaluación base completada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abac1ec",
   "metadata": {},
   "source": [
    "2. Evaluación con distintos thresholds\n",
    "\n",
    "Aquí probamos diferentes valores de `conf` para ver\n",
    "cómo cambian precision y recall sin reentrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8e0498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- BARRIDO DE CONFIDENCE THRESHOLD ---\n",
    "conf_values = [0.1, 0.25, 0.4, 0.6]\n",
    "conf_results = {}\n",
    "\n",
    "for conf in conf_values:\n",
    "    results = model.val(\n",
    "        data=str(DATA_YAML_PATH),\n",
    "        imgsz=cfg[\"img_size\"],\n",
    "        conf=conf,\n",
    "        iou=cfg[\"iou_threshold\"],\n",
    "        batch=cfg[\"batch_size\"],\n",
    "        verbose=False\n",
    "    )\n",
    "    conf_results[conf] = {\n",
    "        \"precision\": float(results.results_dict.get(\"metrics/precision(B)\", 0)),\n",
    "        \"recall\": float(results.results_dict.get(\"metrics/recall(B)\", 0)),\n",
    "        \"mAP50\": float(results.results_dict.get(\"metrics/mAP50(B)\", 0))\n",
    "    }\n",
    "\n",
    "conf_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b7f06",
   "metadata": {},
   "source": [
    "## Interpretación rápida\n",
    "\n",
    "- Si al bajar `conf` mejora mucho el recall → faltan detecciones\n",
    "- Si al subir `conf` mejora precision → hay muchos falsos positivos\n",
    "- Si todo es bajo → el problema es **datos o entrenamiento**, no thresholds\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
