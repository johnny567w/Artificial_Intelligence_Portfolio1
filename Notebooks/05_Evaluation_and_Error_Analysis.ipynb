{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cb96591",
   "metadata": {},
   "source": [
    "# Sexto notebook\n",
    "\n",
    "En este penultimo notebook se  analiza el desempeño real del modelo entrenado para decidir\n",
    "si el bajo rendimiento (si existe) se debe a:\n",
    "- umbrales mal configurados\n",
    "- clases confundidas\n",
    "- pocos datos\n",
    "- o necesidad de más entrenamiento\n",
    "\n",
    "Este notebook:\n",
    "- Evalúa el modelo con distintos thresholds\n",
    "- Analiza predicciones incorrectas\n",
    "- Resume errores por clase\n",
    "- Ayuda a decidir si cambiar a dataset completo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94a0a969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- IMPORTS ---\n",
    "from pathlib import Path\n",
    "import json\n",
    "from collections import defaultdict, Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20f806ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: c:\\Users\\Johnny\\Desktop\\IA\\models\\yolo_best.pt\n",
      "Dataset: c:\\Users\\Johnny\\Desktop\\IA\\data\\processed\\yolo_dataset\\data.yaml\n"
     ]
    }
   ],
   "source": [
    "# --- RUTAS DEL PROYECTO ---\n",
    "#rutas creadas en los previos notebooks\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent\n",
    "\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "YOLO_MODEL_PATH = MODELS_DIR / \"yolo_best.pt\"\n",
    "\n",
    "YOLO_DATASET_DIR = PROJECT_ROOT / \"data\" / \"processed\" / \"yolo_dataset\"\n",
    "DATA_YAML_PATH = YOLO_DATASET_DIR / \"data.yaml\"\n",
    "\n",
    "ARTIFACTS_DIR = PROJECT_ROOT / \"artifacts\"\n",
    "CONFIG_SNAPSHOT_PATH = ARTIFACTS_DIR / \"config_snapshot.json\"\n",
    "\n",
    "print(\"Modelo:\", YOLO_MODEL_PATH)\n",
    "print(\"Dataset:\", DATA_YAML_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45865893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validaciones OK.\n"
     ]
    }
   ],
   "source": [
    "# --- VALIDACIONES ---\n",
    "#es fundamental que ya exista el modelo entrenado y el yaml por eso de debe validar que existen y son consistentes\n",
    "def assert_exists(p: Path, desc: str) -> None:\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Falta {desc}: {p}\")\n",
    "\n",
    "assert_exists(YOLO_MODEL_PATH, \"modelo entrenado\")\n",
    "assert_exists(DATA_YAML_PATH, \"data.yaml\")\n",
    "\n",
    "print(\"Validaciones OK.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "440ae367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target_classes': ['car', 'airplane', 'truck'],\n",
       " 'max_images_per_class_train': 1200,\n",
       " 'max_images_per_class_val': 250,\n",
       " 'img_size': 640,\n",
       " 'batch_size': 16,\n",
       " 'epochs': 20,\n",
       " 'seed': 42,\n",
       " 'conf_threshold': 0.25,\n",
       " 'iou_threshold': 0.5}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- CARGA DE CONFIGURACIÓN ---\n",
    "#carga del archivo .json del modelo yolo\n",
    "with open(CONFIG_SNAPSHOT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "cfg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6591c212",
   "metadata": {},
   "source": [
    "1. Validacion del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02418c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- IMPORTAR YOLO ---\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(str(YOLO_MODEL_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44e4a366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.4.8  Python-3.12.10 torch-2.9.1+cpu CPU (Intel Core 7 150U)\n",
      "Model summary (fused): 73 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 6.71.2 MB/s, size: 152.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Johnny\\Desktop\\IA\\data\\processed\\yolo_dataset\\labels\\val.cache... 550 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 550/550  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 35/35 1.8s/it 1:041.8sss\n",
      "                   all        550       1895      0.571      0.485      0.536      0.361\n",
      "                   car        378       1337       0.52        0.5      0.516      0.332\n",
      "              airplane         97        143      0.808      0.587      0.747      0.522\n",
      "                 truck        250        415      0.385      0.369      0.344      0.229\n",
      "Speed: 1.5ms preprocess, 81.6ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\Johnny\\runs\\detect\\val8\u001b[0m\n",
      "Evaluación base completada.\n"
     ]
    }
   ],
   "source": [
    "# --- EVALUACIÓN BASE (THRESHOLDS POR DEFECTO) ---\n",
    "#Validacion de que si se haya cumpleido los parametros inciiales del rpimer notebook con respetco al consumo de datos, tamanano de imagenes y batch a usarse\n",
    "base_metrics = model.val(\n",
    "    data=str(DATA_YAML_PATH),\n",
    "    imgsz=cfg[\"img_size\"],\n",
    "    conf=cfg[\"conf_threshold\"],\n",
    "    iou=cfg[\"iou_threshold\"],\n",
    "    batch=cfg[\"batch_size\"]\n",
    ")\n",
    "\n",
    "print(\"Evaluación base completada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abac1ec",
   "metadata": {},
   "source": [
    "2. Evaluación con distintos thresholds\n",
    "\n",
    "Aquí probamos diferentes valores de `conf` para ver\n",
    "cómo cambian precision y recall sin reentrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d8e0498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.4.8  Python-3.12.10 torch-2.9.1+cpu CPU (Intel Core 7 150U)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 287.081.6 MB/s, size: 159.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Johnny\\Desktop\\IA\\data\\processed\\yolo_dataset\\labels\\val.cache... 550 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 550/550  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 35/35 1.3s/it 46.7s1.4ss\n",
      "                   all        550       1895      0.571      0.485       0.52      0.337\n",
      "Speed: 0.8ms preprocess, 72.9ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\Johnny\\runs\\detect\\val9\u001b[0m\n",
      "Ultralytics 8.4.8  Python-3.12.10 torch-2.9.1+cpu CPU (Intel Core 7 150U)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 558.1108.0 MB/s, size: 149.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Johnny\\Desktop\\IA\\data\\processed\\yolo_dataset\\labels\\val.cache... 550 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 550/550  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 35/35 1.3s/it 45.2s1.3ss\n",
      "                   all        550       1895      0.571      0.485      0.536      0.361\n",
      "Speed: 0.9ms preprocess, 71.4ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\Johnny\\runs\\detect\\val10\u001b[0m\n",
      "Ultralytics 8.4.8  Python-3.12.10 torch-2.9.1+cpu CPU (Intel Core 7 150U)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 767.4140.0 MB/s, size: 186.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Johnny\\Desktop\\IA\\data\\processed\\yolo_dataset\\labels\\val.cache... 550 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 550/550  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 35/35 1.3s/it 45.1s1.3ss\n",
      "                   all        550       1895       0.59      0.468      0.535      0.372\n",
      "Speed: 0.8ms preprocess, 71.2ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\Johnny\\runs\\detect\\val11\u001b[0m\n",
      "Ultralytics 8.4.8  Python-3.12.10 torch-2.9.1+cpu CPU (Intel Core 7 150U)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 889.9270.0 MB/s, size: 192.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Johnny\\Desktop\\IA\\data\\processed\\yolo_dataset\\labels\\val.cache... 550 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 550/550  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 35/35 1.3s/it 45.8s1.4ss\n",
      "                   all        550       1895      0.727      0.349      0.536      0.391\n",
      "Speed: 0.8ms preprocess, 72.7ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\Johnny\\runs\\detect\\val12\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0.1: {'precision': 0.5708370741630303,\n",
       "  'recall': 0.4854870859286427,\n",
       "  'mAP50': 0.5202825158562202},\n",
       " 0.25: {'precision': 0.5708370741630303,\n",
       "  'recall': 0.4854870859286427,\n",
       "  'mAP50': 0.5359127689191482},\n",
       " 0.4: {'precision': 0.5903571591106672,\n",
       "  'recall': 0.46776135616102815,\n",
       "  'mAP50': 0.5348483211826959},\n",
       " 0.6: {'precision': 0.7271852662841035,\n",
       "  'recall': 0.3485598360511626,\n",
       "  'mAP50': 0.5361896936549514}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- BARRIDO DE CONFIDENCE THRESHOLD ---\n",
    "conf_values = [0.1, 0.25, 0.4, 0.6]\n",
    "conf_results = {}\n",
    "\n",
    "for conf in conf_values:\n",
    "    results = model.val(\n",
    "        data=str(DATA_YAML_PATH),\n",
    "        imgsz=cfg[\"img_size\"],\n",
    "        conf=conf,\n",
    "        iou=cfg[\"iou_threshold\"],\n",
    "        batch=cfg[\"batch_size\"],\n",
    "        verbose=False\n",
    "    )\n",
    "    conf_results[conf] = {\n",
    "        \"precision\": float(results.results_dict.get(\"metrics/precision(B)\", 0)),\n",
    "        \"recall\": float(results.results_dict.get(\"metrics/recall(B)\", 0)),\n",
    "        \"mAP50\": float(results.results_dict.get(\"metrics/mAP50(B)\", 0))\n",
    "    }\n",
    "\n",
    "conf_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b7f06",
   "metadata": {},
   "source": [
    "## Interpretación rápida\n",
    "\n",
    "- Si al bajar `conf` mejora mucho el recall → faltan detecciones\n",
    "- Si al subir `conf` mejora precision → hay muchos falsos positivos\n",
    "- Si todo es bajo → el problema es **datos o entrenamiento**, no thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "167d40b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- PREDICCIONES SOBRE VAL PARA ANÁLISIS DE ERRORES ---\n",
    "VAL_IMAGES_DIR = YOLO_DATASET_DIR / \"images\" / \"val\"\n",
    "VAL_LABELS_DIR = YOLO_DATASET_DIR / \"labels\" / \"val\"\n",
    "\n",
    "predictions_summary = defaultdict(list)\n",
    "\n",
    "results = model.predict(\n",
    "    source=str(VAL_IMAGES_DIR),\n",
    "    imgsz=cfg[\"img_size\"],\n",
    "    conf=cfg[\"conf_threshold\"],\n",
    "    iou=cfg[\"iou_threshold\"],\n",
    "    save=False,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "for r in results:\n",
    "    img_name = Path(r.path).name\n",
    "    detected_classes = [model.names[int(c)] for c in r.boxes.cls.tolist()] if r.boxes is not None else []\n",
    "    predictions_summary[img_name] = detected_classes\n",
    "\n",
    "len(predictions_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efc308bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de imágenes según número de clases detectadas:\n",
      "0 clases detectadas: 64\n",
      "1 clases detectadas: 291\n",
      "2 clases detectadas: 185\n",
      "3 clases detectadas: 10\n"
     ]
    }
   ],
   "source": [
    "# --- ANÁLISIS DE PRESENCIA DE CLASES ---\n",
    "presence_counter = Counter()\n",
    "\n",
    "for classes in predictions_summary.values():\n",
    "    unique = set(classes)\n",
    "    presence_counter[len(unique)] += 1\n",
    "\n",
    "print(\"Cantidad de imágenes según número de clases detectadas:\")\n",
    "for k, v in sorted(presence_counter.items()):\n",
    "    print(f\"{k} clases detectadas:\", v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82e98652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frecuencia de detecciones por clase:\n",
      "- car : 1614\n",
      "- truck : 342\n",
      "- airplane : 125\n"
     ]
    }
   ],
   "source": [
    "# --- FRECUENCIA DE CLASES DETECTADAS ---\n",
    "class_freq = Counter()\n",
    "\n",
    "for classes in predictions_summary.values():\n",
    "    for c in classes:\n",
    "        class_freq[c] += 1\n",
    "\n",
    "print(\"Frecuencia de detecciones por clase:\")\n",
    "for k, v in class_freq.items():\n",
    "    print(\"-\", k, \":\", v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab0da8f",
   "metadata": {},
   "source": [
    "## Decisión técnica\n",
    "\n",
    "Usa estas reglas:\n",
    "\n",
    "- Si **mAP50 < 0.4** y precision/recall bajos → más datos (dataset completo)\n",
    "- Si **precision buena pero recall bajo** → bajar conf o entrenar más epochs\n",
    "- Si **una clase domina y otra casi no aparece** → desbalance de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86ad0a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.10\n",
      "Torch: 2.9.1+cpu\n",
      "CUDA available: False\n",
      "Running on CPU\n"
     ]
    }
   ],
   "source": [
    "# --- CHECK GPU/CPU (PYTORCH) ---\n",
    "import torch, platform\n",
    "print(\"Python:\", platform.python_version())\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "    print(\"VRAM (GB):\", round(torch.cuda.get_device_properties(0).total_memory / (1024**3), 2))\n",
    "else:\n",
    "    print(\"Running on CPU\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
